{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metallic-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as utils\n",
    "from albumentations import (HorizontalFlip, VerticalFlip)\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import nibabel as nib\n",
    "now=time.localtime(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "therapeutic-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,i,data_path, augmentation=True):\n",
    "        self.data_path = data_path\n",
    "        self.data = np.load(data_path+'MRimages_{}.npy'.format(i))\n",
    "        self.target = np.load(data_path+'MASK_{}.npy'.format(i))\n",
    "        self.augmentation = augmentation\n",
    "        print(self.data.shape)\n",
    "        print(self.target.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x= self.data[index]\n",
    "        y = self.target[index]\n",
    "        x,y=self.transform(x,y)\n",
    "        \n",
    "        return x,y\n",
    "    \n",
    "    def transform(self, data, target):\n",
    "        data, target = data_augmentation(data, target, self.augmentation)\n",
    "        return data, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broke-family",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(image, labels, aug=True):\n",
    "    a= random.random()\n",
    "    image = Image.fromarray(image)\n",
    "    mask = Image.fromarray(labels)\n",
    "    if aug :\n",
    "        if a > 0.5 :\n",
    "            augmentated = HorizontalFlip(p=1)(image=np.array (image), mask=np.array(mask))\n",
    "            image = Image.fromarray(augmentated['image'])\n",
    "            mask = Image.fromarray(augmentated['mask'])\n",
    "    data = TF.to_tensor(np.array(image)).float()\n",
    "    masks = TF.to_tensor(np.array(mask)).float()\n",
    "    return data, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compliant-potential",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 = MSE Loss\\n   1 = Cross Entropy Loss\\n   2 = Dice Loss  다이스 로스는 폐기... 멀티 클래스 문제에서 이건 안됨 '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##==============전체 패러미터 입력창 ====================================##\n",
    "\n",
    "number_of_p=5  # 전체 데이터셋 개수\n",
    "img_size = 256 # 3d 복셀이 img_size x img_size x img_size 로 되있다고 생각한다. \n",
    "batch_size=4 # 배치 사이즈 \n",
    "in_dim = 1 # 데이터 한개의 채널 개수. MR은 흑백 이미지 이므로 채널이 한개이다. \n",
    "out_dim = num_class = 6 # 총 분할해야 하는 클래스의 개수. 일단 여기서는 6종류 이므로 6개 이다. \n",
    "num_filters = 64 # 필터개수 \n",
    "num_epoch = 100 # 트레이닝 횟수 \n",
    "lr = 0.001 # learning rate\n",
    "\n",
    "loss_func_switch = 1\n",
    "'''0 = MSE Loss\n",
    "   1 = Cross Entropy Loss\n",
    "   2 = Dice Loss  다이스 로스는 폐기... 멀티 클래스 문제에서 이건 안됨 '''\n",
    "\n",
    "##=======================================================================##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "funded-constitutional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 256)\n",
      "(256, 256, 256)\n",
      "(256, 256, 256)\n",
      "(256, 256, 256)\n",
      "(256, 256, 256)\n",
      "(256, 256, 256)\n",
      "(256, 256, 256)\n",
      "(256, 256, 256)\n",
      "(256, 256, 256)\n",
      "(256, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "train_datasets=[]\n",
    "test_datasets=[]\n",
    "\n",
    "for i in range(1,number_of_p+1):\n",
    "    if i == number_of_p : \n",
    "        test_datasets.append(Dataset(i,'C:/Users/BMPL/Desktop/data set/', augmentation = False))\n",
    "    else:\n",
    "        train_datasets.append(Dataset(i,'C:/Users/BMPL/Desktop/data set/', augmentation = True))\n",
    "\n",
    "traindataset = torch.utils.data.ConcatDataset(train_datasets)\n",
    "trainloader = torch.utils.data.DataLoader(traindataset, batch_size =batch_size, shuffle = True, num_workers=0, pin_memory=False)\n",
    "\n",
    "testdataset = torch.utils.data.ConcatDataset(test_datasets)\n",
    "testloader = torch.utils.data.DataLoader(testdataset, batch_size =1, shuffle = False, num_workers=0, pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "supposed-baghdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor batch_idx,(data,target) in enumerate(trainloader):\\n    inputs, target = data, target\\n    inputs=inputs.squeeze()\\n    target=inputs.squeeze()\\n    print('inputs=%s'%str(inputs.shape))\\n    print('target=%s'%str(target.shape))\\n#f=open('C:/Users/BMPL/Desktop/export{}{}{}{}.txt'.format(now.tm_mon,now.tm_mday,now.tm_hour,now.tm_min),'w')\\n#print(inputs[0][0])\\n#f.write(inputs[0][0])\\n\\nf=open('C:/Users/BMPL/Desktop/export{}{}{}{}.txt'.format(now.tm_mon,now.tm_mday,now.tm_hour,now.tm_min),'w')\\nline=''\\nenter='\\n'\\nspace=' '\\nfor i in list(inputs[0][0]):\\n    line=''\\n    for j in list(i):\\n        line+=str(int(j))\\n        line+=space\\n    line+=enter\\n    f.write(line)\\n    \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for batch_idx,(data,target) in enumerate(trainloader):\n",
    "    inputs, target = data, target\n",
    "    inputs=inputs.squeeze()\n",
    "    target=inputs.squeeze()\n",
    "    print('inputs=%s'%str(inputs.shape))\n",
    "    print('target=%s'%str(target.shape))\n",
    "#f=open('C:/Users/BMPL/Desktop/export{}{}{}{}.txt'.format(now.tm_mon,now.tm_mday,now.tm_hour,now.tm_min),'w')\n",
    "#print(inputs[0][0])\n",
    "#f.write(inputs[0][0])\n",
    "\n",
    "f=open('C:/Users/BMPL/Desktop/export{}{}{}{}.txt'.format(now.tm_mon,now.tm_mday,now.tm_hour,now.tm_min),'w')\n",
    "line=''\n",
    "enter='\\n'\n",
    "space=' '\n",
    "for i in list(inputs[0][0]):\n",
    "    line=''\n",
    "    for j in list(i):\n",
    "        line+=str(int(j))\n",
    "        line+=space\n",
    "    line+=enter\n",
    "    f.write(line)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "retired-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "second-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        act_fn,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def conv_trans_block(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_dim,out_dim, kernel_size=3, stride=2, padding=1,output_padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "        act_fn,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def maxpool():\n",
    "    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    return pool\n",
    "\n",
    "def conv_block_2(in_dim,out_dim,act_fn):\n",
    "    model = nn.Sequential(\n",
    "        conv_block(in_dim,out_dim,act_fn),\n",
    "        nn.Conv2d(out_dim,out_dim, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(out_dim),\n",
    "    )\n",
    "    return model     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "center-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGenerator(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim,num_filter):\n",
    "        super(UnetGenerator,self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.num_filter = num_filter\n",
    "        act_fn = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        print(\"\\n------Initiating U-Net------\\n\")\n",
    "\n",
    "        self.down_1 = conv_block_2(self.in_dim,self.num_filter,act_fn)\n",
    "        self.pool_1 = maxpool()\n",
    "        self.down_2 = conv_block_2(self.num_filter*1,self.num_filter*2,act_fn) # 필터갯수를 두개씩 늘린다. \n",
    "        self.pool_2 = maxpool()\n",
    "        self.down_3 = conv_block_2(self.num_filter*2,self.num_filter*4,act_fn)\n",
    "        self.pool_3 = maxpool()\n",
    "        self.down_4 = conv_block_2(self.num_filter*4,self.num_filter*8,act_fn)\n",
    "        self.pool_4 = maxpool()\n",
    "\n",
    "        self.bridge = conv_block_2(self.num_filter*8,self.num_filter*16,act_fn)\n",
    "\n",
    "        self.trans_1 = conv_trans_block(self.num_filter*16,self.num_filter*8,act_fn) #이게 업 스케일링 하는 거다. \n",
    "        self.up_1 = conv_block_2(self.num_filter*16,self.num_filter*8,act_fn) # 이게 옆에있는 친구 끌고와서 같이 컴볼루젼 하는것, res 넷의 핵심 \n",
    "        self.trans_2 = conv_trans_block(self.num_filter*8,self.num_filter*4,act_fn)\n",
    "        self.up_2 = conv_block_2(self.num_filter*8,self.num_filter*4,act_fn)\n",
    "        self.trans_3 = conv_trans_block(self.num_filter*4,self.num_filter*2,act_fn)\n",
    "        self.up_3 = conv_block_2(self.num_filter*4,self.num_filter*2,act_fn)\n",
    "        self.trans_4 = conv_trans_block(self.num_filter*2,self.num_filter*1,act_fn)\n",
    "        self.up_4 = conv_block_2(self.num_filter*2,self.num_filter*1,act_fn)\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(self.num_filter,self.out_dim,3,1,1))\n",
    "            #nn.Softmax(dim=1))  \n",
    "            #nn.Tanh()) 필수는 아님 시그모이드 함수와 유사하지만, -1~1까지 출력 범위하는 것이 다르다. \n",
    "        \n",
    "            \n",
    "    def forward(self,input):\n",
    "        down_1 = self.down_1(input)\n",
    "        pool_1 = self.pool_1(down_1)\n",
    "        down_2 = self.down_2(pool_1)\n",
    "        pool_2 = self.pool_2(down_2)\n",
    "        down_3 = self.down_3(pool_2)\n",
    "        pool_3 = self.pool_3(down_3)\n",
    "        down_4 = self.down_4(pool_3)\n",
    "        pool_4 = self.pool_4(down_4)\n",
    "\n",
    "        bridge = self.bridge(pool_4)\n",
    "\n",
    "        trans_1 = self.trans_1(bridge)\n",
    "        concat_1 = torch.cat([trans_1,down_4],dim=1)\n",
    "        up_1 = self.up_1(concat_1)\n",
    "        trans_2 = self.trans_2(up_1)\n",
    "        concat_2 = torch.cat([trans_2,down_3],dim=1)\n",
    "        up_2 = self.up_2(concat_2)\n",
    "        trans_3 = self.trans_3(up_2)\n",
    "        concat_3 = torch.cat([trans_3,down_2],dim=1)\n",
    "        up_3 = self.up_3(concat_3)\n",
    "        trans_4 = self.trans_4(up_3)\n",
    "        concat_4 = torch.cat([trans_4,down_1],dim=1)\n",
    "        up_4 = self.up_4(concat_4)\n",
    "        out = self.out(up_4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "operational-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DC(number, m1, m2): # dice score 함수 이다.  넘버는 보고싶은 세크먼테이션의 넘버링이며,  int임  \n",
    "    smooth = 1. \n",
    "    num = m1.size(0)\n",
    "    num2 = m1.size(1)\n",
    "    mx =  np.full((num,num2), number, dtype = np.int64)\n",
    "    mx = TF.to_tensor(mx).squeeze().to(device=device, dtype=torch.int64)\n",
    "    \n",
    "    \n",
    "    mx_m1 = mx==m1\n",
    "    mx_m1 = mx_m1.float()\n",
    "    mx_m2 = mx==m2\n",
    "    mx_m2 = mx_m2.float()\n",
    "    cross_m1_m2 = mx_m1==mx_m2 # 0과 1 둘다 겹치는 부분을 True로 출력함 \n",
    "    \n",
    "    zero_cross_m1_m2 = mx_m1==-1*mx_m2 #0 인데 겹치는 부분만 추출하기 위해서 만든거\n",
    "    \n",
    "    #print(mx_m1.float().sum(),mx_m2.float().sum(), cross_m1_m2.float().sum())\n",
    "    #print(cross_m1_m2.float().sum()-zero_cross_m1_m2.float().sum())\n",
    "    \n",
    "    dc =  (2*(cross_m1_m2.float().sum()-zero_cross_m1_m2.float().sum())+smooth)/(mx_m1.sum()+mx_m2.sum()+smooth)\n",
    "    return dc \n",
    "    \n",
    "def DC_zero(number, m1, m2): # dice score 함수중 0부분에 해당하는 함수 이다.  넘버는 보고싶은 세크먼테이션의 넘버링이며,  int임  \n",
    "    smooth = 1. \n",
    "    num = m1.size(0)\n",
    "    num2 = m1.size(1)\n",
    "    mx =  np.full((num,num2), number, dtype = np.int64)\n",
    "    mx = TF.to_tensor(mx).squeeze().to(device=device, dtype=torch.int64)\n",
    "    \n",
    "    mx_m1 = mx==m1\n",
    "    mx_m1 = mx_m1.float()\n",
    "    mx_m2 = mx==m2\n",
    "    mx_m2 = mx_m2.float()\n",
    "    cross_m1_m2 = m1==100*m2 # m2에 100을 곱하면 나머지 클래스들은 절대 같을수가 없다. 때문에 원래 이미지에서 0끼리겹치는 부분만 나옴    \n",
    "    \n",
    "    #print(mx_m1.sum(),mx_m2.sum(), cross_m1_m2.float().sum())\n",
    "    \n",
    "    dc =  (2*cross_m1_m2.float().sum()+smooth)/(mx_m1.sum()+mx_m2.sum()+smooth)\n",
    "    return dc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sophisticated-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE_Loss(nn.Module):\n",
    "    # y= [4,256,256] , output = [4,6,256,256]\n",
    "    def __init__(self):\n",
    "        super(MSE_Loss,self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward (self, output, y):\n",
    "        soft_max = nn.Softmax(dim =1)\n",
    "        output2 = soft_max(output).to (device)\n",
    "        output2 = output2.permute(0,2,3,1).contiguous().to (device) # 차원을 바꿀때에는 transpose 나 permute를 사용한다. \n",
    "        \n",
    "        one_hot = torch.zeros(batch_size, img_size, img_size, num_class).to (device)\n",
    "        y2 = y.unsqueeze(3).to (device)\n",
    "        y3 = one_hot.scatter_(3, y2, 1). to (device) \n",
    "        # 3이 들어간 이유는 scatter_에서 차원을 맞춰줘야하기 때문이다. [4,256,256,6], [4,256,256,1]의 다른 부분은 dim=3 이기 떄문. \n",
    "        loss = nn.MSELoss()(output2, y3).to (device) \n",
    "        return loss\n",
    "    \n",
    "class Dice_Loss(nn.Module): # 폐기된 함수입니다. ㅜㅜ \n",
    "    # y= [4,256,256] , output = [4,6,256,256]\n",
    "    def __init__(self):\n",
    "        super(Dice_Loss,self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward (self, output, y):\n",
    "        smooth = 1. \n",
    "        \n",
    "        soft_max = nn.Softmax(dim =1)\n",
    "        output2 = soft_max(output).to (device)\n",
    "        output2 = output2.permute(1,0,2,3).contiguous().to (device)\n",
    "        #output2=[6,4,256,256]\n",
    "        self.output2 = output2\n",
    "        self.y = y\n",
    "        \n",
    "        sum_p_list=[]\n",
    "        mul_list = []\n",
    "        w_list = []\n",
    "        loss=1.\n",
    "        #tt=0\n",
    "        for i in range (0,num_class):\n",
    "            if i ==0 :\n",
    "                sum_p, mul, w = self.dice(i)\n",
    "                k = (2*(mul)+smooth)/(sum_p+smooth)\n",
    "                loss-=w*k/num_class\n",
    "    \n",
    "            else:\n",
    "                sum_p, mul, w = self.dice(i)\n",
    "                k = (2*(mul)+smooth)/(sum_p+smooth)\n",
    "                loss-=w*k/num_class\n",
    "            sum_p_list.append(sum_p)\n",
    "            mul_list.append(mul)\n",
    "            #w_list.append(w)\n",
    "               \n",
    "            #tt+=a\n",
    "        #print(tt)\n",
    "       \n",
    "        sum_p_tensor= torch.FloatTensor(sum_p_list).to(device)\n",
    "        mul_tensor = torch.FloatTensor(mul_list).to(device)\n",
    "       # w_tensor = torch.FloatTensor(w_list).to(device)\n",
    "        \n",
    "        #loss =  1. - (2*(mul_tensor).sum()+smooth)/((sum_p_tensor).sum()+smooth)\n",
    "        #loss.requires_grad=True # loss 를 float 으로 출력하게 되는데 이는 TRUE 가 아니라서 문제가 된다. \n",
    "        return loss\n",
    "    \n",
    "    def dice(self, i): # i 는 해당 클래스의 넘버 \n",
    "        output_i = self.output2[i]#output_i = [4,256,256] 각 픽셀이 클래스 i 에 해당될 확률임 \n",
    "        \n",
    "        num, num2, num3 = self.y.size(0), self.y.size(1), self.y.size(2)\n",
    "        mx =  np.full((num,num2,num3), i, dtype = np.int64)\n",
    "        mx = torch.FloatTensor(mx).to(device)\n",
    "    \n",
    "        mx_y = mx==self.y\n",
    "        mx_y = mx_y.float()\n",
    "        \n",
    "        sum_p = mx_y.sum() + output_i.sum()\n",
    "        mul = (mx_y*output_i).sum()\n",
    "        w= batch_size*img_size*img_size/(num_class*mx_y.sum()+1.)\n",
    "        #w = 1/((mx_y.sum())**(2)+1.)\n",
    "        a = output_i.sum()\n",
    "        \n",
    "        return sum_p, mul, w# , a\n",
    "    \n",
    "    def dice_zero(self, i): # i=0 일때 따로 돌린다. 백르라운드 자체가 너무 많기 때문에.. \n",
    "        output_i = self.output2[i]#output_i = [4,256,256] 각 픽셀이 클래스 i 에 해당될 확률임 \n",
    "        \n",
    "        num, num2, num3 = self.y.size(0), self.y.size(1), self.y.size(2)\n",
    "        mx =  np.full((num,num2,num3), i, dtype = np.int64)\n",
    "        mx = torch.FloatTensor(mx).to(device)\n",
    "    \n",
    "        mx_y = mx==self.y\n",
    "        mx_y = mx_y.float()\n",
    "        \n",
    "        sum_p = 2.-mx_y.sum() - output_i.sum()\n",
    "        mul = ((1.-mx_y)*(1.-output_i)).sum()\n",
    "        w= mx_y.sum()\n",
    "        #w = 1/((mx_y.sum())**(2)+1.)\n",
    "        a = output_i.sum()\n",
    "        return sum_p, mul, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "chicken-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(i, x, y, output, export):\n",
    "    zeros=np.zeros((img_size,img_size,1))\n",
    "    x_sample=x[i].cpu()/256\n",
    "    y_sample=y[i].cpu()*50/256\n",
    "    output_sample=output[i].cpu()*50/256 \n",
    "        \n",
    "    x_sample2=np.reshape(x_sample, (img_size, img_size, 1))\n",
    "    y_sample2=np.reshape(y_sample, (img_size, img_size, 1))\n",
    "    ouput_sample2 = np.reshape(output_sample,(img_size,img_size,1))\n",
    "\n",
    "    x_image=np.concatenate((x_sample2, x_sample2, x_sample2), axis = 2)\n",
    "    y_image=np.concatenate(( zeros, y_sample2,  zeros), axis = 2)\n",
    "    output_image=np.concatenate(( zeros, ouput_sample2, zeros), axis = 2)\n",
    "        \n",
    "    origin_image = x_image+y_image\n",
    "    AI_image = x_image+output_image\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(x_image)\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(y_image)\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(output_image)\n",
    "        \n",
    "    if export == True : \n",
    "        plt.savefig('C:/Users/BMPL/Desktop/test_{}.png'.format(i) , dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thick-snowboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 256\n",
      "\n",
      "------Initiating U-Net------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5ce7933812eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 앞서 정의한대로 vGG 클래스를 인스턴스화 하고 지정한 장치에 올립니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnetGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_filter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m##===========================IMPORTANT!!!!!========================================================##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 671\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_batch = len(trainloader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))\n",
    "\n",
    "# 앞서 정의한대로 vGG 클래스를 인스턴스화 하고 지정한 장치에 올립니다.\n",
    "model = UnetGenerator(in_dim=in_dim,out_dim=out_dim,num_filter=num_filters).to(device)\n",
    "\n",
    "##===========================IMPORTANT!!!!!========================================================##\n",
    "# 손실함수 및 최적화함수를 설정합니다.\n",
    "if loss_func_switch == 0 :\n",
    "    MSE_Loss2=MSE_Loss().to(device)\n",
    "    loss_func = MSE_Loss2\n",
    "\n",
    "elif loss_func_switch ==1 :\n",
    "    loss_func =  nn.CrossEntropyLoss()\n",
    "\n",
    "elif loss_func_switch ==2 :\n",
    "    Dice_Loss2 = Dice_Loss().to(device)\n",
    "    loss_func = Dice_Loss2 \n",
    "\n",
    "    \n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.99)\n",
    "optimizer =  torch.optim.Adam(filter(lambda p : p.requires_grad, model.parameters()), lr = lr)# lr = learning rate\n",
    "\n",
    "##=================================================================================================##\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    avg_cost = 0\n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        x, y = data.to(device), target.squeeze().to(device=device, dtype=torch.int64)\n",
    "        # x= [4,1,256,256], y= [4,256,256] , output = [4,6,256,256]\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        \n",
    "        loss = loss_func(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += loss / total_batch\n",
    "        \n",
    "        if batch_idx==10:\n",
    "            output_label = torch.argmax(output, dim=1)\n",
    "            check_output(0, x.squeeze(), y, output_label, export = False)\n",
    "        \n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(i + 1, avg_cost))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del trainloader\n",
    "del x \n",
    "del y\n",
    "torch.cuda.empty_cache()\n",
    "ouput_list=[]\n",
    "x_list=[]\n",
    "y_list=[]\n",
    "with torch.no_grad(): # 그레디언트 계산 안하려고 쓰는 거임 \n",
    "    for batch_idx, (data, target) in enumerate(testloader):\n",
    "        x, y = data.to(device), target.squeeze(0).to(device=device, dtype=torch.int64)\n",
    "        # x= [1,1,256,256], y= [1,256,256] , output = [1,6,256,256]\n",
    "        output = model.forward(x)\n",
    "        \n",
    "        output_label = torch.argmax(output, dim=1)\n",
    "        # ouput_label= [1,256,256]\n",
    "        ouput_list.append(output_label)\n",
    "        x_list.append(x.squeeze(0))\n",
    "        y_list.append(y)\n",
    "    \n",
    "    output_final=torch.cat(ouput_list,dim=0)\n",
    "    x_final = torch.cat(x_list,dim = 0)\n",
    "    y_final = torch.cat(y_list,dim = 0)\n",
    "    \n",
    "    num = output_final.size(0)\n",
    "    \n",
    "    m1 = y_final.view(num, -1)  # Flatten\n",
    "    m2 = output_final.view(num, -1)  # Flatten\n",
    "    \n",
    "    dc_list = []\n",
    "    #print('sum = ', m1.sum(), m2.sum())\n",
    "    #correct_prediction = m1 == m2\n",
    "    #accuracy = correct_prediction.mean()\n",
    "    #print('Accuracy: ', accuracy.item())\n",
    "        \n",
    "    for i in range (num_class):\n",
    "        if i == 0:\n",
    "            dc =  DC_zero(i, m1, m2)\n",
    "            dc_list.append(dc.item())\n",
    "            print('dice coefficient_{}: '.format(i), dc.item())\n",
    "        else :\n",
    "            dc =  DC(i, m1, m2)\n",
    "            dc_list.append(dc.item())\n",
    "            print('dice coefficient_{}: '.format(i), dc.item())\n",
    "    print('dice coefficient_mean: ', sum(dc_list)/len(dc_list))\n",
    "    \n",
    "#ni_img = nib.Nifti1Image(output_final.cpu(), affine=output_final.cpu())\n",
    "#nib.save(ni_img, 'C:/Users/BMPL/Desktop/data set/AI_seg.nii.gz')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "##==============보고싶은 레이어 넘버 입력창 ==============================##\n",
    "n_layer=100\n",
    "##=======================================================================##\n",
    "\n",
    "check_output(n_layer, x_final, y_final, output_final, export = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "q =np.array([[0,1,2],[0,1,2],[0,1,10]])\n",
    "q2=TF.to_tensor(q).squeeze()\n",
    "print(q2)\n",
    "tensor = torch.zeros(3,3)\n",
    "tensor2=tensor==q2\n",
    "\n",
    "print(tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.FloatTensor([[1, 2, 3], [3, 3, 4]])\n",
    "m2 = torch.FloatTensor([[1, 2, 4], [2, 6,3]])\n",
    "print(m1 * m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10.-m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-sailing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
